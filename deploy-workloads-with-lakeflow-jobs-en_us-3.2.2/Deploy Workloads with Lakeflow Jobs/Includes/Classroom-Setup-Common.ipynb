{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7271c91e-301e-415b-9af4-bf5d689c1f72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../../Includes/_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5114940-c027-4ccc-ad3a-6eab7b7e91d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DA = DBAcademyHelper()\n",
    "DA.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0773e855-cbd1-441f-9597-c980854c35fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from databricks.sdk.service import jobs, pipelines\n",
    "from databricks.sdk import WorkspaceClient  \n",
    "\n",
    "class DAJobConfig:\n",
    "    '''\n",
    "    Example\n",
    "    ------------\n",
    "    job_tasks = [\n",
    "        {\n",
    "            'task_name': 'create_table',\n",
    "            'file_path': '/01 - Simple DAB/create_table',\n",
    "            'depends_on': None\n",
    "        },\n",
    "        {\n",
    "            'task_name': 'create_table1',\n",
    "            'file_path': '/01 - Simple DAB/other_table2',\n",
    "            'depends_on': [{'task_key': 'create_table'}]\n",
    "        },\n",
    "        {\n",
    "            'task_name': 'create_table3',\n",
    "            'file_path': '/01 - Simple DAB/other_table2',\n",
    "            'depends_on': [{'task_key': 'create_table'},{'task_key': 'create_table1'}]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "    myjob = DAJobConfig(job_name='test3',\n",
    "                        job_tasks=job_tasks,\n",
    "                        job_parameters=[\n",
    "                            {'name':'target', 'default':'dev'},\n",
    "                            {'name':'catalog_name', 'default':'test'}\n",
    "                        ])\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 job_name: str,\n",
    "                 job_tasks: list[dict],\n",
    "                 job_parameters: list[dict]):\n",
    "    \n",
    "        self.job_name = job_name\n",
    "        self.job_tasks = job_tasks\n",
    "        self.job_parameters = job_parameters\n",
    "        \n",
    "        ## Connect the Workspace\n",
    "        self.w = self.get_workspace_client()\n",
    "\n",
    "        ## Execute methods\n",
    "        self.check_for_duplicate_job_name(check_job_name=self.job_name)\n",
    "        print(f'Job name is unique. Creating the job {self.job_name}...')\n",
    "\n",
    "        self.course_path = self.get_path_one_folder_back()\n",
    "        self.list_job_tasks = self.create_job_tasks()\n",
    "\n",
    "        self.create_job(job_tasks = self.list_job_tasks)\n",
    "\n",
    "\n",
    "    ## Get Workspace client\n",
    "    def get_workspace_client(self):\n",
    "        \"\"\"\n",
    "        Establishes and returns a WorkspaceClient instance for interacting with the Databricks API.\n",
    "        This is set when the object is created within self.w\n",
    "\n",
    "        Returns:\n",
    "            WorkspaceClient: A client instance to interact with the Databricks workspace.\n",
    "        \"\"\"\n",
    "        w = WorkspaceClient()\n",
    "        return w\n",
    "\n",
    "\n",
    "    # Check if the job name already exists, return error if it does.\n",
    "    def check_for_duplicate_job_name(self, check_job_name: str):\n",
    "        for job in self.w.jobs.list():\n",
    "            if job.settings.name == check_job_name:\n",
    "                test_job_name = False\n",
    "                assert test_job_name, f'You already have a job with the same name. Please manually delete the job {self.job_name}'                \n",
    "\n",
    "\n",
    "    ## Store the path of one folder one folder back\n",
    "    def get_path_one_folder_back(self):\n",
    "        current_path = os.getcwd()\n",
    "        print(f'Using the following path to reference the Files: {current_path}/.')\n",
    "        return current_path\n",
    "\n",
    "\n",
    "    ## Create the job tasks\n",
    "    def create_job_tasks(self):\n",
    "        all_job_tasks = []\n",
    "        for task in job_tasks:\n",
    "            if task.get('file_path', False) != False:\n",
    "\n",
    "                ## Create a list of jobs.TaskDependencies\n",
    "                task_dependencies = [jobs.TaskDependency(task_key=depend_task['task_key']) for depend_task in task['depends_on']] if task['depends_on'] else None\n",
    "\n",
    "                ## Create the task\n",
    "                job_task_File = jobs.Task(task_key=task['task_name'],\n",
    "                                         notebook_task=jobs.NotebookTask(notebook_path=self.course_path+task['file_path']),\n",
    "                                         depends_on=task_dependencies,\n",
    "                                         timeout_seconds=0)\n",
    "                all_job_tasks.append(job_task_File)\n",
    "\n",
    "            elif task.get('pipeline_task', False) != False:\n",
    "                job_task_dlt = jobs.Task(task_key=task['task_name'],\n",
    "                                         pipeline_task=jobs.PipelineTask(pipeline_id=task['pipeline_id'], full_refresh=True),\n",
    "                                         timeout_seconds=0)\n",
    "                all_job_tasks.append(job_task_info)\n",
    "\n",
    "        return all_job_tasks\n",
    "    \n",
    "\n",
    "    def set_job_parameters(self, parameters: dict):\n",
    "\n",
    "        job_params_list = []\n",
    "        for param in self.job_parameters:\n",
    "            job_parameter = jobs.JobParameterDefinition(name=param['name'], default=param['default'])\n",
    "            job_params_list.append(job_parameter)\n",
    "\n",
    "        return job_params_list\n",
    "    \n",
    "\n",
    "    ## Create final job\n",
    "    def create_job(self, job_tasks: list[jobs.Task]):\n",
    "        created_job = self.w.jobs.create(\n",
    "                name=self.job_name,\n",
    "                tasks=job_tasks,\n",
    "                parameters = self.set_job_parameters(self.job_parameters)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14363efd-a2c4-47c6-911f-50ab1ad73ea5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@DBAcademyHelper.add_method\n",
    "def print_job_config(self, job_name_extension, file_paths, Files, job_tasks=None, check_task_dependencies=False):\n",
    "    \"\"\"\n",
    "    - Prints an HTML output in the cell below with information about the Job Name and Files to use with the path for each user.\n",
    "    - Method also sets the required job name, job Files, and tasks in the DA object as attributes to use for validation testing.\n",
    "\n",
    "    Parameters:\n",
    "        - job_name_extension (str): Specify what you want your job name extension to be: (schema_{job_name_extension}).\n",
    "        - file_paths (str): Uses the a folder where the executing program lives.\n",
    "            Example: /Task Files/Lesson 1 Files\n",
    "        - Files (list[str]) : List of File names in the file_paths folder location\n",
    "            Example: ['01-reset','02-ingest']\n",
    "        - job_task_names (dict{'task':[list of dependencies]}) : Dictionary of the required task names for the job and their dependencies as a dictionary. Leave as None if you do not want to check the tasks.\n",
    "            Example:\n",
    "                job_tasks={\n",
    "                    'Ingest_CSV': [],\n",
    "                    'Create_Invalid_Table': ['Ingest_CSV'],\n",
    "                    'Create_Valid_Table': ['Ingest_CSV','Create_Invalid_Table']\n",
    "                }\n",
    "        - check_task_dependencies (boolean) : Determines whether to check for dependencies in job tasks. Leave as False if you don't want to check the dependencies.\n",
    "\n",
    "    Returns:\n",
    "        - Return HTML output with the specified string information\n",
    "        - Attributes\n",
    "            - user_required_job_name that holds the required job name\n",
    "            - user_reuqired_job_Files that holds a list of required Files\n",
    "            - user_required_job_task_names = job tasks and dependencies\n",
    "            - check_task_dependencies = value if needs to check for dependencies\n",
    "\n",
    "    Example:\n",
    "        DA.print_job_config(\n",
    "            job_name_extension='Lesson_02',\n",
    "            file_paths='/Task Files/Lesson 2 Files',\n",
    "            Files=[\n",
    "                '2.01 - Ingest CSV',\n",
    "                '2.02 - Create Invalid Table',\n",
    "                '2.02 - Create Valid Table'\n",
    "            ],\n",
    "            job_tasks={\n",
    "                'Ingest_CSV': [],\n",
    "                'Create_Invalid_Table': ['Ingest_CSV'],\n",
    "                'Create_Valid_Table': ['Ingest_CSV','Create_Invalid_Table']\n",
    "            },\n",
    "            check_task_dependencies = True\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    ## Get current path of File\n",
    "    base_path = dbutils.entry_point.getDbutils().notebook().getContext().notebookPath().getOrElse(None)\n",
    "\n",
    "    ## Concatenates the schema name of the user with the job name\n",
    "    required_job_name = f\"{job_name_extension}_{self.schema_name}\"\n",
    "\n",
    "    ## Goes back two paths to main course folder\n",
    "    main_course_folder_path = \"/Workspace\" + \"/\".join(base_path.split(\"/\")[:-1]) + file_paths + '/'\n",
    "\n",
    "    ## Create paths for each File specified in method argument Files(list of Files to use)\n",
    "    Files_to_print = []\n",
    "    for i, File in enumerate(Files):\n",
    "        current_file_path = (f'File #{i + 1}', main_course_folder_path + File)\n",
    "        Files_to_print.append(current_file_path)\n",
    "\n",
    "\n",
    "    ## Use the display_config_values function to display the following values as HTML output.\n",
    "    ## Will list the Job Name and File paths.\n",
    "    self.display_config_values([\n",
    "            ('Job Name', required_job_name)\n",
    "        ] + Files_to_print)\n",
    "    \n",
    "    ## Store the current job name, Files to use, tasks and if to check task dependencies.\n",
    "    self.user_required_job_name = required_job_name\n",
    "    self.user_required_job_Files = [item[1] for item in Files_to_print]\n",
    "    self.user_required_job_task_names = job_tasks\n",
    "    self.check_task_dependencies = check_task_dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f2e6f31-4f6e-4630-84a7-7da99c5c8164",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def create_sql_editor_file(sql_query: str,\n",
    "                           folder_path: str,\n",
    "                           filename: str,\n",
    "                           default_catalog: str,\n",
    "                           default_schema: str) -> None:\n",
    "    \"\"\"Create a Databricks SQL Editor notebook file (.dbquery.ipynb).\n",
    "\n",
    "    This function generates a Databricks-compatible `.dbquery.ipynb` file\n",
    "    containing a single SQL cell. It can be used to export queries from\n",
    "    Databricks SQL Editor into a notebook format.\n",
    "\n",
    "    Args:\n",
    "        sql_query (str): The SQL query to include in the notebook.\n",
    "        folder_path (str): Path to the folder where the file will be saved.\n",
    "        filename (str): Base name of the file (without extension).\n",
    "        default_catalog (str): Default catalog name to store in metadata.\n",
    "        default_schema (str): Default schema name to store in metadata.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified folder does not exist.\n",
    "\n",
    "    Returns:\n",
    "        None: The function writes a file to disk and prints a confirmation.\n",
    "\n",
    "    Example:\n",
    "        >>> import os\n",
    "        >>> create_sql_editor_file(\n",
    "        ...     sql_query=\"SELECT * FROM samples.nyctaxi.trips;\",\n",
    "        ...     folder_path=os.getcwd(),\n",
    "        ...     filename=\"test_new_function\",\n",
    "        ...     default_catalog=\"workspace\",\n",
    "        ...     default_schema=\"default\"\n",
    "        ... )\n",
    "        Created the file '/current/dir/test_new_function.dbquery.ipynb'.\n",
    "    \"\"\"\n",
    "    # Ensure the folder exists\n",
    "    if os.path.isdir(folder_path) == True:\n",
    "        pass\n",
    "    elif os.path.isdir(folder_path) == False:\n",
    "        folder_path = os.getcwd()\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"The folder '{folder_path}' does not exist.\")\n",
    "\n",
    "    notebook_content = {\n",
    "        \"cells\": [\n",
    "            {\n",
    "                \"cell_type\": \"code\",\n",
    "                \"execution_count\": 0,\n",
    "                \"metadata\": {\n",
    "                    \"application/vnd.databricks.v1+cell\": {\n",
    "                        \"cellMetadata\": {\n",
    "                            \"byteLimit\": 10485760,\n",
    "                            \"rowLimit\": 1000\n",
    "                        },\n",
    "                        \"inputWidgets\": {},\n",
    "                        \"nuid\": \"e9847359-a7e7-435e-9478-e7207b2f02e6\",\n",
    "                        \"showTitle\": False,\n",
    "                        \"tableResultSettingsMap\": {},\n",
    "                        \"title\": \"\"\n",
    "                    }\n",
    "                },\n",
    "                \"outputs\": [],\n",
    "                \"source\": [sql_query]\n",
    "            }\n",
    "        ],\n",
    "        \"metadata\": {\n",
    "            \"application/vnd.databricks.v1+notebook\": {\n",
    "                \"computePreferences\": None,\n",
    "                \"dashboards\": [],\n",
    "                \"environmentMetadata\": None,\n",
    "                \"inputWidgetPreferences\": None,\n",
    "                \"language\": \"sql\",\n",
    "                \"notebookMetadata\": {\n",
    "                    \"sqlQueryOptions\": {\n",
    "                        \"applyAutoLimit\": True,\n",
    "                        \"catalog\": default_catalog,\n",
    "                        \"schema\": default_schema\n",
    "                    }\n",
    "                },\n",
    "                \"notebookName\": filename,\n",
    "                \"widgets\": {}\n",
    "            },\n",
    "            \"language_info\": {\"name\": \"sql\"}\n",
    "        },\n",
    "        \"nbformat\": 4,\n",
    "        \"nbformat_minor\": 0\n",
    "    }\n",
    "\n",
    "    # Full file path\n",
    "    file_path = os.path.join(folder_path, f\"{filename}.dbquery.ipynb\")\n",
    "\n",
    "    # Write notebook to file\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(notebook_content, f, indent=2)\n",
    "\n",
    "    print(f\"Created the file '{file_path}'.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Classroom-Setup-Common",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
