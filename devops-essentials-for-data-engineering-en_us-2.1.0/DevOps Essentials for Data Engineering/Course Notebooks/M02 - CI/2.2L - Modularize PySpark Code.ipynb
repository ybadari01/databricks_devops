{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bcafcaee-a35a-4c08-8a14-8debaae48d55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6f59f2d-13cf-46b4-b77d-f2a14f6e635e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 2.2 Lab - Modularize PySpark Code\n",
    "\n",
    "### Estimated Duration: 15-20 minutes\n",
    "\n",
    "By the end of this lab, you will practice analyzing a PySpark script by breaking it down into smaller, reusable functions, and assessing how well their changes improve the code's clarity and ease of maintenance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9f16f51-f8b2-4c4a-9ddd-1ba64d938836",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "\n",
    "Follow these steps to select the classic compute cluster:\n",
    "\n",
    "\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "\n",
    "2. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "\n",
    "   - Click **More** in the drop-down.\n",
    "\n",
    "   - In the **Attach to an existing compute resource** window, use the first drop-down to select your unique cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "\n",
    "2. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "\n",
    "3. Wait a few minutes for the cluster to start.\n",
    "\n",
    "4. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6838b4c0-2036-4319-92ae-94370a2104ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A. Classroom Setup\n",
    "\n",
    "Run the following cell to configure your working environment for this course. \n",
    "\n",
    "**NOTE:** The `DA` object is only used in Databricks Academy courses and is not available outside of these courses. It will dynamically reference the information needed to run the course.\n",
    "\n",
    "##### The notebook \"2.1 - Modularizing PySpark Code - Required\" sets up the catalogs for this course. If you have not run this notebook, the catalogs will not be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0329c4e-3abf-48b8-a3c1-90feede6cde8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-2.2L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7571c6fe-be86-411f-8e05-9f788ea0f10e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Run the cell below to view your current default catalog and schema. \n",
    "\n",
    "  Confirm the following:\n",
    "- The default catalog is your unique catalog name (shown above).\n",
    "- The current schema is **default**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a79ea944-d628-4856-8977-122385857f88",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"current_catalog()\":294},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1768134811320}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT current_catalog(), current_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdd04f55-95fd-4826-85d8-d5d4f300249d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## B. Review the Provided PySpark Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5dbf5c4e-30bf-4ff2-ac95-a476d243866f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Run the cell below to preview the **samples.nyctaxi.trips** table. Confirm the table exists and view the data.\n",
    "\n",
    "    Notice the following:\n",
    "    - All columns are in lower case\n",
    "    - **trip_distance** is currently in miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2340634-c302-4f57-88ee-fd74a14d2294",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM samples.nyctaxi.trips \n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d54aff8-9c08-4af3-8da2-e9840decf0de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. You have been provided with the following PySpark script that performs the following:\n",
    "\n",
    "   a. Reads from the **samples.nyctaxi.trips** table.\n",
    "\n",
    "   b. Creates a new column named **trip_distance_km** that converts **trip_distance** to kilometers and rounds it to two decimal places.\n",
    "\n",
    "   c. Converts all of the column names to uppercase.\n",
    "\n",
    "   d. Saves the DataFrame as a table named **nyc_lab_solution_table** in your specific catalog (`DA.catalog_name`).\n",
    "\n",
    "   Run the cell below and confirm that the **nyc_lab_solution_table** table was created with all uppercase column names and the new **trip_distance_km** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5276ab4-cbd8-4dfe-86e3-abcf8fe8be20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Run the code to view the default catalog the table is being written to.\n",
    "print(DA.catalog_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e184f08c-ddee-47cb-a540-244829dc6209",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Load the data and create a new column named trip_distance_km\n",
    "new_taxi = (spark\n",
    "            .read\n",
    "            .table(\"samples.nyctaxi.trips\")\n",
    "            .withColumn(\"trip_distance_km\", F.round(F.col(\"trip_distance\") * 1.60934, 2))\n",
    "        )\n",
    "\n",
    "\n",
    "## Upper case all columns\n",
    "new_taxi = new_taxi.select([F.col(col).alias(col.upper()) for col in new_taxi.columns])\n",
    "\n",
    "\n",
    "## Save the table to the your catalog\n",
    "(new_taxi\n",
    " .write\n",
    " .mode('overwrite')\n",
    " .saveAsTable(f'{DA.catalog_name}.default.nyc_lab_solution_table')\n",
    ")\n",
    "\n",
    "## View the final table\n",
    "display(spark.table(f'{DA.catalog_name}.default.nyc_lab_solution_table'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd761190-0083-4e47-bf47-f06dd5f6c915",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## C. Modularize the PySpark Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0da0c329-12f8-42fa-b122-fb5768fcdac2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Your task is to take the provided Spark code from above and break it down into modular functions. Each function should perform a specific part of the task, making it easier to test, reuse, and maintain.\n",
    "\n",
    "    There are a variety of ways to solve this problem. For consistency in this example, create the following functions:\n",
    "\n",
    "    - `convert_miles_to_km`: Converts a column from miles to kilometers and rounds the result to two decimal places.\n",
    "\n",
    "    - `uppercase_column_names`: Converts all column names in the DataFrame to uppercase.\n",
    "\n",
    "    - `load_data`: Reads the table.\n",
    "\n",
    "    - `save_to_catalog`: Saves the DataFrame as a new table in your catalog.\n",
    "\n",
    "**NOTE:** The `load_data` and `save_to_catalog` functions have already been created for you. \n",
    "\n",
    "**TO DO:** Create the `convert_miles_to_km` and `uppercase_column_names` in the cell below.\n",
    "\n",
    "**HINT:** The solution functions can be found in **[./src_lab/lab_functions/transforms.py]($./src_lab/lab_functions/transforms.py)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc276945-e507-4400-81f0-4a61a6d01d7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "## load_data has already been created for you\n",
    "def load_data(table_name):\n",
    "    return spark.read.table(table_name)\n",
    "\n",
    "\n",
    "## save_to_catalog has been created for you\n",
    "def save_to_catalog(df, catalog_name, schema_name, table_name):\n",
    "    (df\n",
    "     .write\n",
    "     .mode('overwrite')\n",
    "     .saveAsTable(f'{catalog_name}.{schema_name}.{table_name}')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd2270fb-3cd0-4c17-a22b-38d72d9eedfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## convert_miles_to_km\n",
    "def convert_miles_to_km(df, new_column_name, miles_column):\n",
    "    return df.withColumn(new_column_name, F.round(F.col(miles_column ) * 1.60934, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdd9e4eb-f3ed-496e-9a53-6d647b41aae2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "## convert_miles_to_km\n",
    "def convert_miles_to_km(df, new_column_name, miles_column):\n",
    "    return df.withColumn(new_column_name, F.round(F.col(miles_column) * 1.60934, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0fa838d-81f2-4873-ab2c-c331ed419d88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## uppercase_column_names\n",
    "def uppercase_columns_names(df):\n",
    "    return df.select([F.col(col).alias(col.upper()) for col in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0683de16-2e9a-4b7e-80f0-7fafa5ed8eb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "## uppercase_column_names\n",
    "def uppercase_columns_names(df):\n",
    "    return df.select([F.col(col).alias(col.upper()) for col in df.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43c8c43e-d685-4b49-931f-7e898a6efd30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Run your functions to obtain the same results as the original PySpark code. The `save_to_catalog` function will name your new table **my_lab_table**. \n",
    "\n",
    "**NOTE:** If you are receiving a schema mismatch error that is because you are trying to overwrite a table you created with a different schema. Delete the table and recreate the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6721146f-6fb5-49a9-9b20-cf6916bfafef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Load table\n",
    "df = load_data(\"samples.nyctaxi.trips\")\n",
    "\n",
    "## Convert miles to km\n",
    "## TODO - Add your function here\n",
    "df = convert_miles_to_km(df, new_column_name = \"trip_distance_km\", miles_column = \"trip_distance\")\n",
    "\n",
    "## Upcase column\n",
    "## TODO - Add your function here\n",
    "df = uppercase_columns_names(df)\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {DA.catalog_name}.default.my_lab_table\")\n",
    "\n",
    "\n",
    "## Save DataFrame as a table in your catalog\n",
    "save_to_catalog(df, catalog_name = DA.catalog_name, schema_name=\"default\", table_name = \"my_lab_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d7a61fb-8edc-4fa1-8831-81620c957270",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "## Load table\n",
    "df = load_data(\"samples.nyctaxi.trips\")\n",
    "\n",
    "## Convert miles to km\n",
    "df = convert_miles_to_km(df, new_column_name = \"trip_distance_km\", miles_column = \"trip_distance\")\n",
    "\n",
    "## Upcase column\n",
    "df = uppercase_columns_names(df)\n",
    "\n",
    "## Save DataFrame as a table in your catalog\n",
    "save_to_catalog(df, catalog_name = DA.catalog_name, schema_name=\"default\", table_name = \"my_lab_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2df426f8-6ed8-44f3-b0b4-e5c8b1f50841",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. Run the following cell to test that the original table created in cell 11 (**nyc_km_solution_table**) is the same as your new table created by the functions above (**my_lab_table**). The test uses the PySpark `assertDataFrameEqual` method.\n",
    "\n",
    "    If there is an error, it means the original table is not the same as your new table, and you need to fix your functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e690259-7453-47ba-bb4f-038722b49e10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.testing.utils import assertDataFrameEqual\n",
    "\n",
    "# Read the tables (solution and your created table)\n",
    "solution_df = spark.read.table(f\"{DA.catalog_name}.default.nyc_lab_solution_table\")\n",
    "user_df = spark.read.table(f\"{DA.catalog_name}.default.my_lab_table\")\n",
    "\n",
    "# Use assertDataFrameEqual to compare the two tables. Return an error if the tables are different.\n",
    "assertDataFrameEqual(solution_df, user_df)\n",
    "\n",
    "print(\"The tables are identical! Functions were created correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77077a37-4ab0-4616-b8d7-1a91321d5197",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7846212960180005,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "2.2L - Modularize PySpark Code",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
