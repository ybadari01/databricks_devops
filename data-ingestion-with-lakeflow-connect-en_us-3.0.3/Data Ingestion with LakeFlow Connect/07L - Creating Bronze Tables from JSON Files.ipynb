{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "660d8a1b-a2ed-4128-906e-73715d10e234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c1a860d-58f0-46e0-ab49-7539c6c06fd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Lab - Creating Bronze Tables from JSON Files\n",
    "### Duration: ~ 15 minutes\n",
    "\n",
    "In this lab you will ingest a JSON file as Delta table and then flatten the JSON formatted string column.\n",
    "\n",
    "### Learning Objectives\n",
    "  - Inspect a raw JSON file.\n",
    "  - Read in JSON files to a Delta table and flatten the JSON formatted string column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d83ff852-9b50-4c79-9f1f-45410be7e384",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default and you have a Shared SQL warehouse.\n",
    "\n",
    "<!-- ![Select Cluster](./Includes/images/selecting_cluster_info.png) -->\n",
    "\n",
    "Follow these steps to select the classic compute cluster:\n",
    "\n",
    "\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "\n",
    "2. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "\n",
    "   - Click **More** in the drop-down.\n",
    "\n",
    "   - In the **Attach to an existing compute resource** window, use the first drop-down to select your unique cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "\n",
    "2. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "\n",
    "3. Wait a few minutes for the cluster to start.\n",
    "\n",
    "4. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef608772-ea8d-498c-9f16-1a7b727c6b6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## A. Classroom Setup\n",
    "\n",
    "Run the following cell to configure your working environment for this notebook.\n",
    "\n",
    "**NOTE:** The `DA` object is only used in Databricks Academy courses and is not available outside of these courses. It will dynamically reference the information needed to run the course in the lab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "763aba64-1dea-40c7-99f1-bf945e8cf542",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Includes/Classroom-Setup-07L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08aa5c4a-0a4b-4fa3-b057-ccba50ba60d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Run the cell below to view your default catalog and schema. Notice that your default catalog is **dbacademy** and your default schema is your unique **labuser** schema.\n",
    "\n",
    "**NOTE:** The default catalog and schema are pre-configured for you to avoid the need to specify the three-level name when writing your tables (i.e., catalog.schema.table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b9cdffd-f55f-48ad-96b1-4444da6f9686",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT current_catalog(), current_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "169449e8-21c7-4992-a89f-aa94019816f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## B. Lab - JSON Ingestion\n",
    "**Scenario:** You are working with your data team on ingesting a JSON file into Databricks. Your job is to ingest the JSON file as is into a bronze table, then create a second bronze table that flattens the JSON formatted string column in the raw bronze table for downstream processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c31e1b78-0b22-4ca4-8529-074cabc2d64a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### B1. Inspect the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac5647cb-9496-450a-a791-57cd52bf9567",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. In the cell below, view the value of the Python variable `DA.paths.working_dir`. This variable will reference your **dbacademy.ops.labuser** volume, as each user has a different source volume. This variable is created within the classroom setup script to dynamically reference your unique volume.\n",
    "\n",
    "   Run the cell and review the results. Youâ€™ll notice that the `DA.paths.working_dir` variable points to your `/Volumes/dbacademy/ops/labuser` volume.\n",
    "\n",
    "**Note:** Instead of using the `DA.paths.working_dir` variable, you could also specify the path name directly by right clicking on your volume and selecting **Copy volume path**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fdb1641-cad8-4913-8344-a107ae604283",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "print(DA.paths.working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8456baa4-8c97-402e-be1b-7a4f409670a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Run the cell to view the data in the `/Volumes/dbacademy/ops/your-labuser-name/json_demo_files/lab_kafka_events.json` file in the location from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c29488b6-1ab8-4ed7-bd1c-3d09a56ac26c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "spark.sql(f'''\n",
    "          SELECT * \n",
    "          FROM json.`{DA.paths.working_dir}/json_demo_files/lab_kafka_events.json`\n",
    "          ''').display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3420a9b-cdd5-411a-881c-1a4a249fdf0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### B2. Create the Raw Bronze Table\n",
    "\n",
    "Inspect and run the code below to ingest the raw JSON file `/Volumes/dbacademy/ops/your-labuser-name/json_demo_files/lab_kafka_events.json` and create the **lab7_lab_kafka_events_raw** table.\n",
    "\n",
    "Notice the following:\n",
    "- The **value** column is decoded.\n",
    "- The **decoded_value** column was created and returns the decoded column as a JSON-formatted string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f1d8929-dfe6-4e66-8a26-0abcd9d702e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE lab7_lab_kafka_events_raw\n",
    "AS\n",
    "SELECT \n",
    "  *,\n",
    "  cast(unbase64(value) as STRING) as decoded_value\n",
    "FROM read_files(\n",
    "        DA.paths_working_dir || '/json_demo_files/lab_kafka_events.json',\n",
    "        format => \"json\", \n",
    "        schema => '''\n",
    "          key STRING, \n",
    "          timestamp DOUBLE, \n",
    "          value STRING\n",
    "        ''',\n",
    "        rescueddatacolumn => '_rescued_data'\n",
    "      );\n",
    "\n",
    "-- View the table\n",
    "SELECT *\n",
    "FROM lab7_lab_kafka_events_raw;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65c3b106-c33b-4c99-a25c-3352ddad1f2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### B3. Create the Flattened Bronze Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fca09323-cac7-452b-9e31-ce6fff737b1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Your goal is to flatten the JSON formatted string column **decoded_value** from the table **lab7_lab_kafka_events_raw** to create a new table named **lab7_lab_kafka_events_flattened** for downstream processing. The table should contain the following columns:\n",
    "    - **key**\n",
    "    - **timestamp**\n",
    "    - **user_id**\n",
    "    - **event_type**\n",
    "    - **event_timestamp**\n",
    "    - **items**\n",
    "\n",
    "    You can use whichever technique you prefer:\n",
    "\n",
    "    - Parse the JSON formatted string (easiest) to flatten\n",
    "      - [Query JSON strings](https://docs.databricks.com/aws/en/semi-structured/json):\n",
    "\n",
    "    - Convert the JSON formatted string as a VARIANT and flatten\n",
    "      - [parse_json function](https://docs.databricks.com/gcp/en/sql/language-manual/functions/parse_json)\n",
    "\n",
    "    - Convert the JSON formatted string to a STRUCT and flatten\n",
    "      - [schema_of_json function](https://docs.databricks.com/aws/en/sql/language-manual/functions/schema_of_json)\n",
    "      - [from_json function](https://docs.databricks.com/gcp/en/sql/language-manual/functions/from_json)\n",
    "\n",
    "**NOTE:** View the lab solution notebook to view the solutions for each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5a658b7-7883-4d93-81ed-102ef8aa93ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. To begin, run the code below to view the final solution table **lab7_lab_kafka_events_flattened_solution**. This will give you an idea of what your final table should look like.\n",
    "\n",
    "  **NOTE**: Depending on your solution, the data types of the columns may vary slightly.  \n",
    "\n",
    "\n",
    "##### Optional Challenge\n",
    "\n",
    "  As a challenge, after flattening the table, try converting the data types accordingly. Depending on your skill set, you may not convert all columns to the correct data types within the allotted time.\n",
    "\n",
    "  - **key** STRING\n",
    "  - **timestamp** DOUBLE\n",
    "  - **user_id** STRING\n",
    "  - **event_type** STRING\n",
    "  - **event_timestamp** TIMESTAMP\n",
    "  - **items** (STRUCT or VARIANT) depending on the method you used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cbed2fc-9f66-4805-9abc-cc40a8781f84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT *\n",
    "FROM lab7_lab_kafka_events_flattened_solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "156cf298-b220-4611-904a-d430ce9325fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. Write the query in the cell below to read the **lab_kafka_events_raw** table and create the flattened table **lab7_lab_kafka_events_flattened** following the requirements from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "181d823d-9d93-4812-be12-dd8221be5049",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "<FILL-IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d3a95cf-5adc-4a7b-9f04-62d0aec49e20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "---- Parse the JSON formatted STRING\n",
    "CREATE OR REPLACE TABLE lab7_lab_kafka_events_flattened_str\n",
    "AS\n",
    "SELECT \n",
    "  key,\n",
    "  timestamp,\n",
    "  decoded_value:user_id,\n",
    "  decoded_value:event_type,\n",
    "  cast(decoded_value:event_timestamp AS TIMESTAMP),\n",
    "  from_json(decoded_value:items,'ARRAY<STRUCT<item_id: STRING, price_usd: DOUBLE, quantity: BIGINT>>') AS items\n",
    "FROM lab7_lab_kafka_events_raw;\n",
    "\n",
    "\n",
    "---- Display the table\n",
    "SELECT *\n",
    "FROM lab7_lab_kafka_events_flattened_str;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c423c99-6aea-4f13-b074-7de6341af6a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "<FILL-IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e3437e8-9bff-4833-bcfb-03d8bb6c8419",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "---- Convert the JSON formatted string as a VARIANT\n",
    "---- NOTE: The VARIANT decoded_value_variant column is included in this solution to display the column\n",
    "---- NOTE: Variant data type will not work on Serverless Version 1.\n",
    "CREATE OR REPLACE TABLE lab7_lab_kafka_events_flattened_variant\n",
    "AS\n",
    "SELECT\n",
    "  key,\n",
    "  timestamp,\n",
    "  parse_json(decoded_value) AS decoded_value_variant,\n",
    "  cast(decoded_value_variant:user_id AS STRING),\n",
    "  decoded_value_variant:event_type :: STRING,\n",
    "  decoded_value_variant:event_timestamp :: TIMESTAMP,\n",
    "  decoded_value_variant:items\n",
    "FROM lab7_lab_kafka_events_raw;\n",
    "\n",
    "\n",
    "---- Display the table\n",
    "SELECT *\n",
    "FROM lab7_lab_kafka_events_flattened_variant;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d1cb2f5-382e-453a-847e-f56da9038668",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "<FILL-IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f14a278-f273-43c8-9308-4b6569c36d83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "---- Convert the JSON formatted string as a STRUCT\n",
    "\n",
    "---- Return the structure of the JSON formatted string\n",
    "SELECT schema_of_json(decoded_value)\n",
    "FROM lab7_lab_kafka_events_raw\n",
    "LIMIT 1;\n",
    "\n",
    "\n",
    "---- Use the JSON structure from above within the from_json function to convert the JSON formatted string to a STRUCT\n",
    "---- NOTE: The STRUCT decoded_value_struct column is included in this solution to display the column\n",
    "CREATE OR REPLACE TABLE lab7_lab_kafka_events_flattened_struct\n",
    "AS\n",
    "SELECT\n",
    "  key,\n",
    "  timestamp,\n",
    "  from_json(decoded_value, 'STRUCT<event_timestamp: STRING, event_type: STRING, items: ARRAY<STRUCT<item_id: STRING, price_usd: DOUBLE, quantity: BIGINT>>, user_id: STRING>') AS decoded_value_struct,\n",
    "  decoded_value_struct.user_id,\n",
    "  decoded_value_struct.event_type,\n",
    "  cast(decoded_value_struct.event_timestamp AS TIMESTAMP),\n",
    "  decoded_value_struct.items\n",
    "FROM lab7_lab_kafka_events_raw;\n",
    "\n",
    "\n",
    "---- Display the table\n",
    "SELECT *\n",
    "FROM lab7_lab_kafka_events_flattened_struct;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2cea1d2-1546-4c7d-9bee-933e6830e38e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3635044395472592,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "07L - Creating Bronze Tables from JSON Files",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
