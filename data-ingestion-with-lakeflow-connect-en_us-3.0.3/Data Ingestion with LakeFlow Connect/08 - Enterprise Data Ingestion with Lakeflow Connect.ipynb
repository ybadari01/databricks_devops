{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c8aceb4-5181-41e9-8c0e-d1ca92de96bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b90fae7-7bd2-4b10-a347-ba7b37cdc89a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 8 - Enterprise Data Ingestion with LakeFlow Connect\n",
    "\n",
    "In this demonstration, you will be introduced to **LakeFlow Connect** managed connectors for external enterprise sources. An easy-to-use tool for bringing data from various systems such as databases (e.g., SQL Server), applications (e.g., Salesforce, Workday), and file storage services (e.g., SharePoint) into the lakehouse. \n",
    "\n",
    "It is designed to handle data efficiently and automatically improve performance.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of the demonstration, you should be able to:\n",
    "\n",
    "- Explore the available Databricks managed connectors to ingest data through LakeFlow Connect.\n",
    "- View how to ingest data using Partner connect.\n",
    "- Add a Database connector and configure an ingestion pipeline demonstration:\n",
    "  - Choose which data you want to ingest and synchronize to Databricks\n",
    "  - Synchronize the data pipeline to Unity Catalog (catalog and schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ad613fa-e725-4749-98f4-e29c5cf0d71a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Complete the following to view the Lakeflow Connect documentation:\n",
    "\n",
    "   a. Go to the [Databricks documentation](https://docs.databricks.com/aws/en/) page.\n",
    "\n",
    "   b. In the left navigation bar, expand **Data Engineering**.\n",
    "\n",
    "   c. Expand **Lakeflow Connect** to view the available documentation for data ingestion with Lakeflow Connect.\n",
    "\n",
    "   d. Expand **Managed Connectors** to access information about Databricks-managed connectors.\n",
    "\n",
    "**NOTE:** Please note that the documentation directions may change during an update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2af3df58-ae20-489a-8893-4c3ce8667ad1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Complete the following to explore the available **Data Ingestion** capabilities in Databricks:\n",
    "\n",
    "   a. On the left main navigation bar, right-click on **Data Ingestion** and select **Open in a New Tab**.\n",
    "\n",
    "   b. Under **Databricks Connectors**, you'll see various Databricks-managed connectors provided by LakeFlow Connect.\n",
    "\n",
    "   c. Under the **Files** section, you can:\n",
    "   \n",
    "   - **Create or modify tables**\n",
    "\n",
    "   - **Upload files to a volume**\n",
    "\n",
    "   - **Create a table from Amazon S3**\n",
    "   \n",
    "   - Drag and drop files when using the options to create/modify tables or upload files to a volume.\n",
    "\n",
    "   d. Under **Fivetran Connectors**, you can search for specific data source connections using a partner.\n",
    "\n",
    "   e. Click on any connector to view details.\n",
    "\n",
    "   f. You can also upload files directly to **DBFS** for backward compatibility, though Databricks recommends uploading to Unity Catalog moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12706aa5-8a76-42c8-a8ee-69e8bdc96f8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. Complete the following point-and-click demonstration to learn how to use a Databricks managed connector to an external database or SaaS application using **LakeFlow Connect**.\n",
    "\n",
    "      **NOTE:** This course does not have an active database or SaaS application to use. The demos below are a simple walk through. During a live teach, pick one of the tours below.\n",
    "\n",
    "   - [LakeFlow Connect Managed Connector Demonstration](https://app.getreprise.com/launch/BXZY58n/) - Simple demonstration\n",
    "\n",
    "   - [Databricks Lakeflow Connect for Workday Reports: Connect, Ingest, and Analyze Workday Data Without Complexity](https://www.databricks.com/resources/demos/tours/appdev/lakeflow-workday-connect?itm_data=demo_center)\n",
    "\n",
    "   - [Databricks Lakeflow Connect for Salesforce: Powering Smarter Selling with AI and Analytics](https://www.databricks.com/resources/demos/tours/platform/discover-databricks-lakeflow-connect-demo?itm_data=demo_center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f7ee0ff-b9ad-46ec-869d-de93bdc05ed3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "08 - Enterprise Data Ingestion with Lakeflow Connect",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
