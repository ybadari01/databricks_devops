{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af122513-9389-4e61-a0ef-c656e59c93d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Classroom-Setup-Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58bb7499-b493-4984-9832-973a3e301d51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "USE CATALOG dbacademy;\n",
    "USE SCHEMA IDENTIFIER(DA.schema_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6005c384-2784-42e8-9037-a4de2524d5b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import random\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Function to create one event with nested array\n",
    "def create_event(i: int) -> dict:\n",
    "    value_dict = {\n",
    "        \"user_id\": f\"user_{random.randint(1000, 9999)}\",\n",
    "        \"event_type\": random.choice([\"click\", \"purchase\", \"view\"]),\n",
    "        \"event_timestamp\": datetime.now().isoformat(),\n",
    "        \"items\": [\n",
    "            {\n",
    "                \"item_id\": f\"item_{random.randint(100, 999)}\",\n",
    "                \"quantity\": random.randint(1, 5),\n",
    "                \"price_usd\": round(random.uniform(10.0, 100.0), 2)\n",
    "            }\n",
    "            for _ in range(random.randint(1, 3))  # 1 to 3 items per event\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Encode value as JSON string, then base64\n",
    "    encoded_value = base64.b64encode(json.dumps(value_dict).encode()).decode()\n",
    "\n",
    "    return {\n",
    "        \"key\": f\"event_{i}\",\n",
    "        \"timestamp\": datetime.now().timestamp(),\n",
    "        \"value\": encoded_value\n",
    "    }\n",
    "\n",
    "# Create 100 records\n",
    "events = [create_event(i) for i in range(100)]\n",
    "\n",
    "\n",
    "username_cleaned = DA.username.replace('.', '_')\n",
    "# Output file path\n",
    "output_path = Path(f'/Volumes/dbacademy/ops/{username_cleaned}/json_demo_files/lab_kafka_events.json')\n",
    "\n",
    "# Write to file\n",
    "with open(output_path, \"w\") as f:\n",
    "    for event in events:\n",
    "        json.dump(event, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"Generated file: {output_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "605ba92e-7685-46ba-82e7-4e000dc3719e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import random\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "def create_valid_event(i: int) -> dict:\n",
    "    value_payload = {\n",
    "        \"user_id\": f\"user_{random.randint(1000, 9999)}\",\n",
    "        \"event_type\": random.choice([\"click\", \"purchase\", \"view\"]),\n",
    "        \"event_timestamp\": datetime.now().isoformat(),\n",
    "        \"items\": [\n",
    "            {\n",
    "                \"item_id\": f\"item_{random.randint(100, 999)}\",\n",
    "                \"quantity\": random.randint(1, 5),\n",
    "                \"price_usd\": round(random.uniform(10.0, 100.0), 2)\n",
    "            }\n",
    "            for _ in range(random.randint(1, 3))\n",
    "        ]\n",
    "    }\n",
    "    value_json = json.dumps(value_payload)\n",
    "    value_base64 = base64.b64encode(value_json.encode('utf-8')).decode('utf-8')\n",
    "\n",
    "    return {\n",
    "        \"key\": f\"event_{i}\",\n",
    "        \"timestamp\": datetime.now().timestamp(),  # correct timestamp\n",
    "        \"value\": value_base64\n",
    "    }\n",
    "\n",
    "def create_malformed_event(i: int) -> dict:\n",
    "    value_payload = {\n",
    "        \"user_id\": f\"user_{random.randint(1000, 9999)}\",\n",
    "        \"event_type\": \"malformed_event\",\n",
    "        \"event_timestamp\": datetime.now().isoformat(),\n",
    "        \"items\": []\n",
    "    }\n",
    "    value_json = json.dumps(value_payload)\n",
    "    value_base64 = base64.b64encode(value_json.encode('utf-8')).decode('utf-8')\n",
    "\n",
    "    return {\n",
    "        \"key\": f\"event_{i}\",\n",
    "        \"timestamp\": \"ERROR\",  # <-- invalid timestamp\n",
    "        \"value\": value_base64\n",
    "    }\n",
    "\n",
    "# Create 99 valid events\n",
    "events = [create_valid_event(i) for i in range(99)]\n",
    "\n",
    "# Add 1 malformed event at a random position\n",
    "malformed_event = create_malformed_event(99)\n",
    "insert_position = random.randint(0, 99)\n",
    "events.insert(insert_position, malformed_event)\n",
    "\n",
    "\n",
    "username_cleaned = DA.username.replace('.', '_')\n",
    "# Output file path\n",
    "output_path = Path(f'/Volumes/dbacademy/ops/{username_cleaned}/json_demo_files/lab_kafka_events_challenge.json')\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    for event in events:\n",
    "        json.dump(event, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"File written with 1 malformed 'timestamp' at position {insert_position}: {output_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf97be12-2da9-4967-bed9-e1f4ff35189c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create solution table\n",
    "CREATE OR REPLACE TABLE lab7_lab_kafka_events_raw\n",
    "AS\n",
    "SELECT \n",
    "  *,\n",
    "  cast(unbase64(value) as STRING) as decoded_value\n",
    "FROM read_files(\n",
    "        DA.paths_working_dir || '/json_demo_files/lab_kafka_events.json',\n",
    "        format => \"json\", \n",
    "        schema => '''\n",
    "          key STRING, \n",
    "          timestamp DOUBLE, \n",
    "          value STRING\n",
    "        ''',\n",
    "        rescueddatacolumn => '_rescued_data'\n",
    "      );\n",
    "\n",
    "\n",
    "-- Create the solution table with the correct data types\n",
    "DROP TABLE IF EXISTS lab7_lab_kafka_events_flattened_solution;\n",
    "\n",
    "CREATE OR REPLACE TABLE lab7_lab_kafka_events_flattened_solution\n",
    "AS\n",
    "SELECT \n",
    "  key,\n",
    "  timestamp,\n",
    "  decoded_value:user_id,\n",
    "  decoded_value:event_type,\n",
    "  cast(decoded_value:event_timestamp AS TIMESTAMP),\n",
    "  from_json(decoded_value:items,'ARRAY<STRUCT<item_id: STRING, price_usd: DOUBLE, quantity: BIGINT>>') AS items\n",
    "FROM lab7_lab_kafka_events_raw;\n",
    "\n",
    "\n",
    "DROP TABLE IF EXISTS lab7_lab_kafka_events_raw;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31112416-9d10-40a3-80c3-dbe2fc3a8192",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # This builds the final table so students can view how their table should look during the lab. \n",
    "\n",
    "# # Build v1_lab_kafka_events: Decode base64 and capture rescued data\n",
    "# query_1 = f\"\"\"\n",
    "# SELECT\n",
    "#   * EXCEPT (_rescued_data),\n",
    "#   CAST(unbase64(value) AS STRING) AS decoded_value,\n",
    "#   _rescued_data\n",
    "# FROM READ_FILES(\n",
    "#   CONCAT('{DA.paths.working_dir}', '/json_demo_files/lab_kafka_events.json'),\n",
    "#   FORMAT => 'json',\n",
    "#   schemaHints => 'key STRING, timestamp STRING, value STRING, _rescued_data STRING'\n",
    "# )\n",
    "# \"\"\"\n",
    "\n",
    "# # Build v2_lab_kafka_events: Parse the decoded_value as STRUCT\n",
    "# query_2 = f\"\"\"\n",
    "# SELECT \n",
    "# CAST(key as STRING),\n",
    "# CAST(timestamp as DOUBLE),\n",
    "#   FROM_JSON(\n",
    "#     decoded_value,\n",
    "#     'STRUCT<\n",
    "#       event_timestamp: STRING,\n",
    "#       event_type: STRING,\n",
    "#       items: ARRAY<STRUCT<\n",
    "#         item_id: STRING,\n",
    "#         price_usd: DOUBLE,\n",
    "#         quantity: BIGINT\n",
    "#       >>,\n",
    "#       user_id: STRING\n",
    "#     >'\n",
    "#   ) AS value,\n",
    "#   _rescued_data\n",
    "# FROM (\n",
    "#   {query_1}\n",
    "# )\n",
    "# \"\"\"\n",
    "\n",
    "# # Drop the table 07_lab_kafka_events if it exists\n",
    "# query_3 = \"\"\"\n",
    "# DROP TABLE IF EXISTS 07_lab_solution;\n",
    "# \"\"\"\n",
    "\n",
    "# # Create table 07_lab_kafka_events using query_2\n",
    "# query_4 = f\"\"\"\n",
    "# CREATE TABLE 07_lab_solution AS\n",
    "# SELECT\n",
    "#   key,\n",
    "#   timestamp,\n",
    "#   value.event_timestamp AS event_timestamp,\n",
    "#   value.event_type AS event_type,\n",
    "#   GET(value.items, 0).item_id AS item_id,\n",
    "#   GET(value.items, 0).price_usd AS price_usd,\n",
    "#   GET(value.items, 0).quantity AS quantity,\n",
    "#   value.user_id AS user_id\n",
    "# FROM (\n",
    "#     {query_2}\n",
    "# )\n",
    "# \"\"\"\n",
    "\n",
    "# # Execute the queries\n",
    "# spark.sql(query_3)\n",
    "# spark.sql(query_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a0f2cac-9862-47ed-a154-4ac1efb928c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # This builds the challenge table for students in case they need assistance. \n",
    "\n",
    "# query_5 = \"\"\"\n",
    "# DROP TABLE IF EXISTS 07_lab_challenge_solution;\n",
    "# \"\"\"\n",
    "\n",
    "# query_6 = f\"\"\"\n",
    "# CREATE TABLE 07_lab_challenge_solution AS \n",
    "# SELECT \n",
    "# * EXCEPT (timestamp),\n",
    "# COALESCE(\n",
    "#   timestamp,\n",
    "#   case when from_json(_rescued_data, 'timestamp STRING')['timestamp'] = \"ERROR\" then 1759180800.0 else null end\n",
    "# ) as timestamp_fixed \n",
    "# FROM READ_FILES(\n",
    "#         CONCAT('{DA.paths.working_dir}', '/json_demo_files/lab_kafka_events.json'),\n",
    "#         FORMAT => \"json\",\n",
    "#         schemaHints => 'key STRING, timestamp DOUBLE, value STRING'\n",
    "#       );\n",
    "# \"\"\"\n",
    "\n",
    "# # Execute the queries\n",
    "# spark.sql(query_5)\n",
    "# spark.sql(query_6)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Classroom-Setup-07L",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
