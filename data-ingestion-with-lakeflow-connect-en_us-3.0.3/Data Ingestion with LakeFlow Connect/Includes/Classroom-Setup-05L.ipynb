{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41c89c8a-4037-4ec9-839d-af3596737e67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Classroom-Setup-Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08bda2e4-691d-4f65-9184-cabe75447f88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "USE CATALOG dbacademy;\n",
    "USE SCHEMA IDENTIFIER(DA.schema_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "baeb4c50-5750-4c3d-a3a5-fa127c556445",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_directory_in_user_volume(user_default_volume_path: str, create_folders: list):\n",
    "    '''\n",
    "    Creates multiple (or single) directories in the specified volume path.\n",
    "\n",
    "    Args:\n",
    "    -------\n",
    "        user_default_volume_path (str): The base directory path where the folders will be created. \n",
    "                                        You can use the default DA.paths.working_dir as the user's volume path.\n",
    "        create_folders (list): A list of strings representing folder names to be created within the base directory.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "        None: This function does not return any values but prints log information about the created directories.\n",
    "\n",
    "    Example: \n",
    "    -------\n",
    "    create_directory_in_user_volume(user_default_volume_path=DA.paths.working_dir, create_folders=['customers', 'orders', 'status'])\n",
    "    '''\n",
    "    \n",
    "    print('----------------------------------------------------------------------------------------')\n",
    "    for folder in create_folders:\n",
    "\n",
    "        create_folder = f'{user_default_volume_path}/{folder}'\n",
    "\n",
    "        if not os.path.exists(create_folder):\n",
    "        # If it doesn't exist, create the directory\n",
    "            dbutils.fs.mkdirs(create_folder)\n",
    "            print(f'Creating folder: {create_folder}')\n",
    "\n",
    "        else:\n",
    "            print(f\"Directory {create_folder} already exists. No action taken.\")\n",
    "        \n",
    "    print('----------------------------------------------------------------------------------------\\n')\n",
    "\n",
    "create_directory_in_user_volume(user_default_volume_path = DA.paths.working_dir, create_folders = ['csv_demo_files', 'json_demo_files', 'xml_demo_files'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eac72740-d829-47c7-95ce-ba5418dd4c69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def corrupt_row(input_csv, output_csv):\n",
    "    \"\"\"\n",
    "    Keeps only the first 5 rows and first 3 columns,\n",
    "    and replaces the first order_id value with 'aaa'.\n",
    "    \"\"\"\n",
    "    with open(input_csv, mode='r', newline='', encoding='utf-8') as infile:\n",
    "        reader = csv.reader(infile, delimiter='|')\n",
    "        rows = list(reader)\n",
    "\n",
    "    # Keep only the first 5 rows and first 3 columns\n",
    "    trimmed_rows = [row[:3] for row in rows[:5]]\n",
    "\n",
    "    # Replace the first order_id in the first data row (row index 1) with 'aaa'\n",
    "    if len(trimmed_rows) > 1:\n",
    "        trimmed_rows[3][0] = 'M_PREM_A,Premium Queen Mattress,#$%^'\n",
    "        trimmed_rows[3][0] = 'M_PREM_A,Premium Queen Mattress,$100.00'\n",
    "\n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter='|')\n",
    "        writer.writerows(trimmed_rows)\n",
    "\n",
    "username_cleaned = DA.username.replace('.', '_')\n",
    "# Example usage\n",
    "corrupt_row(\n",
    "    '/Volumes/dbacademy_ecommerce/v01/raw/products-csv/part-00000-tid-1663954264736839188-daf30e86-5967-4173-b9ae-d1481d3506db-2367-1-c000.csv',\n",
    "    f'/Volumes/dbacademy/ops/{username_cleaned}/csv_demo_files/lab_malformed_data.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1c9c9ef-9530-4c04-bda4-9cf8c028860a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Builds the final lab table for students to use as a resource\n",
    "query_1 = \"\"\"\n",
    "DROP TABLE IF EXISTS 05_lab_solution\n",
    "\"\"\"\n",
    "\n",
    "query_2 = f\"\"\"\n",
    "CREATE TABLE 05_lab_solution \n",
    "USING DELTA AS\n",
    "SELECT\n",
    "  *,\n",
    "  _METADATA.FILE_MODIFICATION_TIME AS file_modification_time,\n",
    "  _METADATA.FILE_NAME AS source_file, \n",
    "  current_timestamp() as ingestion_time\n",
    "FROM READ_FILES(\n",
    "        CONCAT('{DA.paths.working_dir}', '/csv_demo_files/lab_malformed_data.csv'),\n",
    "        FORMAT => \"csv\",\n",
    "        SEP => \",\",\n",
    "        HEADER => true,\n",
    "        SCHEMA => 'item_id STRING, name STRING, price DOUBLE', \n",
    "        RESCUEDDATACOLUMN => \"_rescued_data\"\n",
    "      )\n",
    "\"\"\"\n",
    "\n",
    "# Execute the queries\n",
    "spark.sql(query_1)\n",
    "spark.sql(query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37044662-e8aa-4249-bceb-149f9011555c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Builds the final lab challenge table for students to use as a resource\n",
    "query_1 = \"\"\"\n",
    "DROP TABLE IF EXISTS 05_lab_challenge_solution\n",
    "\"\"\"\n",
    "\n",
    "query_2 = f\"\"\"\n",
    "CREATE TABLE 05_lab_challenge_solution \n",
    "AS\n",
    "SELECT\n",
    "  item_id,\n",
    "  name,\n",
    "  price,\n",
    "  coalesce(price,replace(_rescued_data:price,'$','')) AS price_fixed,\n",
    "  _rescued_data,\n",
    "  _metadata.file_modification_time AS file_modification_time,\n",
    "  _metadata.file_name AS source_file, \n",
    "  current_timestamp() as ingestion_time\n",
    "FROM read_files(\n",
    "        concat('{DA.paths.working_dir}', '/csv_demo_files/lab_malformed_data.csv'),\n",
    "        format => \"csv\",\n",
    "        sep => \",\",\n",
    "        header => true,\n",
    "        schema => 'item_id STRING, name STRING, price DOUBLE', \n",
    "        rescueddatacolumn => \"_rescued_data\"\n",
    "      )\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Execute the queries\n",
    "r = spark.sql(query_1)\n",
    "r = spark.sql(query_2)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Classroom-Setup-05L",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
