{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d2aa9fd-bb6a-437c-8424-cc58016b2828",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../../Includes/_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eaa8faeb-2fdf-4669-80ae-db8c68ac285e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DA = DBAcademyHelper()\n",
    "DA.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00ce6c16-ea66-4f9e-9061-e4b01c2e5975",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- CREATE DA VARIABLE USING SQL FOR USER INFORMATION FROM THE META TABLE FOR SQL SCRIPTS\n",
    "\n",
    "-- Create a temp view storing information from the obs table.\n",
    "CREATE OR REPLACE TEMP VIEW user_info AS\n",
    "SELECT map_from_arrays(collect_list(replace(key,'.','_')), collect_list(value))\n",
    "FROM dbacademy.ops.meta;\n",
    "\n",
    "-- Create SQL dictionary var (map)\n",
    "DECLARE OR REPLACE DA MAP<STRING,STRING>;\n",
    "\n",
    "-- Set the temp view in the DA variable\n",
    "SET VAR DA = (SELECT * FROM user_info);\n",
    "\n",
    "DROP VIEW IF EXISTS user_info;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2ffd866-d7a3-44b2-b9bd-a35c3470b56c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_volume(in_catalog: str, in_schema: str, volume_name: str):\n",
    "    '''\n",
    "    Create a volume in the specified catalog.schema.\n",
    "    '''\n",
    "    print(f'Creating volume: {in_catalog}.{in_schema}.{volume_name} if not exists.\\n')\n",
    "    r = spark.sql(f'CREATE VOLUME IF NOT EXISTS {in_catalog}.{in_schema}.{volume_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "144f6888-d18f-4be2-9950-499d2d302b2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def delete_source_files(source_files: str):\n",
    "    \"\"\"\n",
    "    Deletes all files in the specified source volume.\n",
    "\n",
    "    This function iterates through all the files in the given volume,\n",
    "    deletes them, and prints the name of each file being deleted.\n",
    "\n",
    "    Parameters:\n",
    "    - source_files : str\n",
    "        The path to the volume containing the files to delete. \n",
    "        Use the {DA.paths.working_dir} to dynamically navigate to the user's volume location in dbacademy/ops/vocareumlab@name:\n",
    "            Example: DA.paths.working_dir = /Volumes/dbacademy/ops/vocareumlab@name\n",
    "\n",
    "    Returns:\n",
    "    - None. This function does not return any value. It performs file deletion and prints all files that it deletes. If no files are found it prints in the output.\n",
    "\n",
    "    Example:\n",
    "    - delete_source_files(f'{DA.paths.working_dir}/pii/stream_source/user_reg')\n",
    "    \"\"\"\n",
    "\n",
    "    import os\n",
    "\n",
    "    print(f'\\nSearching for files in {source_files} volume to delete prior to creating files...')\n",
    "    if os.path.exists(source_files):\n",
    "        list_of_files = sorted(os.listdir(source_files))\n",
    "    else:\n",
    "        list_of_files = None\n",
    "\n",
    "    if not list_of_files:  # Checks if the list is empty.\n",
    "        print(f\"No files found in {source_files}.\\n\")\n",
    "    else:\n",
    "        for file in list_of_files:\n",
    "            file_to_delete = source_files + file\n",
    "            print(f'Deleting file: {file_to_delete}')\n",
    "            dbutils.fs.rm(file_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "583d59d6-8567-41c9-996b-2dfa95a2e316",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_directory_in_user_volume(user_default_volume_path: str, create_folders: list):\n",
    "    '''\n",
    "    Creates multiple (or single) directories in the specified volume path.\n",
    "\n",
    "    Args:\n",
    "    -------\n",
    "        user_default_volume_path (str): The base directory path where the folders will be created. \n",
    "                                        You can use the default DA.paths.working_dir as the user's volume path.\n",
    "        create_folders (list): A list of strings representing folder names to be created within the base directory.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "        None: This function does not return any values but prints log information about the created directories.\n",
    "\n",
    "    Example: \n",
    "    -------\n",
    "    create_directory_in_user_volume(user_default_volume_path=DA.paths.working_dir, create_folders=['customers', 'orders', 'status'])\n",
    "    '''\n",
    "    \n",
    "    print('----------------------------------------------------------------------------------------')\n",
    "    for folder in create_folders:\n",
    "\n",
    "        create_folder = f'{user_default_volume_path}/{folder}'\n",
    "\n",
    "        if not os.path.exists(create_folder):\n",
    "        # If it doesn't exist, create the directory\n",
    "            dbutils.fs.mkdirs(create_folder)\n",
    "            print(f'Creating folder: {create_folder}')\n",
    "\n",
    "        else:\n",
    "            print(f\"Directory {create_folder} already exists. No action taken.\")\n",
    "        \n",
    "    print('----------------------------------------------------------------------------------------\\n')\n",
    "\n",
    "\n",
    "create_directory_in_user_volume(user_default_volume_path = DA.paths.working_dir, create_folders = ['csv_demo_files', 'json_demo_files', 'xml_demo_files'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d84f4fed-07b1-4a46-8cff-493d59a19763",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def copy_files(copy_from: str, copy_to: str, n: int, sleep=2):\n",
    "    '''\n",
    "    Copy files from one location to another destination's volume.\n",
    "\n",
    "    This method performs the following tasks:\n",
    "      1. Lists files in the source directory and sorts them. Sorted to keep them in the same order when copying for consistency.\n",
    "      2. Verifies that the source directory has at least `n` files.\n",
    "      3. Copies files from the source to the destination, skipping files already present at the destination.\n",
    "      4. Pauses for `sleep` seconds after copying each file.\n",
    "      5. Stops after copying `n` files or if all files are processed.\n",
    "      6. Will print information on the files copied.\n",
    "    \n",
    "    Parameters\n",
    "    - copy_from (str): The source directory where files are to be copied from.\n",
    "    - copy_to (str): The destination directory where files will be copied to.\n",
    "    - n (int): The number of files to copy from the source. If n is larger than total files, an error is returned.\n",
    "    - sleep (int, optional): The number of seconds to pause after copying each file. Default is 2 seconds.\n",
    "\n",
    "    Returns:\n",
    "    - None: Prints information to the log on what files it's loading. If the file exists, it skips that file.\n",
    "\n",
    "    Example:\n",
    "    - copy_files(copy_from='/Volumes/gym_data/v01/user-reg', \n",
    "           copy_to=f'{DA.paths.working_dir}/pii/stream_source/user_reg',\n",
    "           n=1)\n",
    "    '''\n",
    "    import os\n",
    "    import time\n",
    "\n",
    "    print(f\"\\n----------------Loading files to user's volume: '{copy_to}'----------------\")\n",
    "\n",
    "    ## List all files in the copy_from volume and sort the list\n",
    "    list_of_files_to_copy = sorted(os.listdir(copy_from))\n",
    "    total_files_in_copy_location = len(list_of_files_to_copy)\n",
    "\n",
    "    ## Get a list of files in the source\n",
    "    list_of_files_in_source = os.listdir(copy_to)\n",
    "\n",
    "    assert total_files_in_copy_location >= n, f\"The source location contains only {total_files_in_copy_location} files, but you specified {n}  files to copy. Please specify a number less than or equal to the total number of files available.\"\n",
    "\n",
    "    ## Looping counter\n",
    "    counter = 1\n",
    "\n",
    "    ## Load files if not found in the co\n",
    "    for file in list_of_files_to_copy:\n",
    "      if file.startswith('_'):\n",
    "        pass\n",
    "      else:\n",
    "        ## If the file is found in the source, skip it with a note. Otherwise, copy file.\n",
    "        if file in list_of_files_in_source:\n",
    "          print(f'File number {counter} - {file} is already in the source volume \"{copy_to}\". Skipping file.')\n",
    "        else:\n",
    "          file_to_copy = f'{copy_from}{file}'\n",
    "          copy_file_to = f'{copy_to}{file}'\n",
    "          print(f'File number {counter} - Copying file {file_to_copy} --> {copy_file_to}.')\n",
    "          dbutils.fs.cp(file_to_copy, copy_file_to , recurse = True)\n",
    "          \n",
    "          ## Sleep after load\n",
    "          time.sleep(sleep) \n",
    "\n",
    "        ## Stop after n number of loops based on argument.\n",
    "        if counter == n:\n",
    "          break\n",
    "        else:\n",
    "          counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a012d3c8-12cb-4e38-8034-1126b7129c72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def drop_tables(in_catalog: str, in_schema: list, dry_run: bool = False):\n",
    "    \"\"\"\n",
    "    Drops all tables and views in the specified schema within a given catalog.\n",
    "\n",
    "    Args:\n",
    "        in_catalog (str): The catalog name (e.g., 'dbacademy_peter').\n",
    "        in_schema (str): The schema name (e.g., 'default').\n",
    "        dry_run (bool): If True, only prints tables that would be dropped without actually dropping them.\n",
    "\n",
    "    Returns:\n",
    "        list: Fully qualified names of the tables that were dropped (or would be dropped in dry-run mode).\n",
    "\n",
    "    Example:\n",
    "    >>> drop_tables(in_catalog='dbacademy_peter', in_schema='1_bronze_db')\n",
    "    \"\"\"\n",
    "    # Check if catalog exists\n",
    "    catalogs = [row.catalog for row in spark.sql(\"SHOW CATALOGS\").collect()]\n",
    "    if in_catalog not in catalogs:\n",
    "        raise ValueError(f\"Catalog '{in_catalog}' does not exist.\")\n",
    "\n",
    "    ## Delete tables and views in schema\n",
    "    for schema in in_schema:\n",
    "        \n",
    "        # Check if schema exists in the catalog\n",
    "        full_schema = f\"{in_catalog}.{schema}\"\n",
    "        if not spark.catalog.databaseExists(full_schema):\n",
    "            raise ValueError(f\"Schema '{schema}' does not exist in catalog '{in_catalog}'.\")\n",
    "        \n",
    "        print(f\"\\n{'Previewing' if dry_run else 'Dropping'} all tables in {in_catalog}.{schema}:\")\n",
    "\n",
    "        # Get all tables in the schema\n",
    "        tables = spark.sql(f\"SHOW TABLES IN {in_catalog}.{schema}\").collect()\n",
    "\n",
    "        if not tables:\n",
    "            print(f\"No tables found in schema {in_catalog}.{schema}. Nothing to drop.\")\n",
    "        else:\n",
    "            table_names = [f\"{in_catalog}.{schema}.{t.tableName}\" for t in tables]\n",
    "\n",
    "            for table_full_name in table_names:\n",
    "                if dry_run:\n",
    "                    print(f\"Would drop: {table_full_name}\")\n",
    "                else:\n",
    "                    try:\n",
    "                        spark.sql(f\"DROP TABLE IF EXISTS {table_full_name}\")\n",
    "                        print(f\"Dropped TABLE: {table_full_name}\")\n",
    "                    except:\n",
    "                        spark.sql(f\"DROP VIEW IF EXISTS {table_full_name}\")\n",
    "                        print(f\"Dropped VIEW: {table_full_name}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Classroom-Setup-Common",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
